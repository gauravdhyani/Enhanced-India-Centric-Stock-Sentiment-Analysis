{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9rOUUk0-8M7"
      },
      "source": [
        "# **Enhanced-India-Centric-Stock-Sentiment-Analysis-JSON-Generator**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zBcfzRaHpnm",
        "outputId": "bf61b09d-4cb2-4654-b8c9-f10d66f2a1ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved to ./output.json\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import json\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Paths\n",
        "model_dir = \"content/final_model\"\n",
        "tokenizer_dir = \"content/final_tokenizer\"\n",
        "input_csv = \"/content/headlines.csv\"\n",
        "output_json = \"./output.json\"\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_dir)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Label mapping\n",
        "label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(input_csv)\n",
        "\n",
        "# Ensure text column\n",
        "if \"Headline\" not in df.columns:\n",
        "    raise ValueError(\"CSV must contain 'Headline' column\")\n",
        "df[\"Headline\"] = df[\"Headline\"].astype(str)\n",
        "\n",
        "# Tokenize\n",
        "encodings = tokenizer(list(df[\"Headline\"]), truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "input_ids = encodings[\"input_ids\"].to(device)\n",
        "attention_mask = encodings[\"attention_mask\"].to(device)\n",
        "\n",
        "# Predict\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    scores, preds = torch.max(probs, dim=1)\n",
        "\n",
        "# Prepare JSON\n",
        "results = []\n",
        "for headline, pred, score in zip(df[\"Headline\"], preds.cpu().numpy(), scores.cpu().numpy()):\n",
        "    results.append({\n",
        "        \"headline\": headline,\n",
        "        \"sentiment\": f\"LABEL_{pred}\",\n",
        "        \"score\": float(score)\n",
        "    })\n",
        "\n",
        "# Save JSON\n",
        "with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_json}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
